import { generateText } from "ai";
import { createGeminiProvider } from "ai-sdk-provider-gemini-cli";

// Initialize the Gemini provider with OAuth (subscription-based)
const gemini = createGeminiProvider({
  authType: "oauth-personal",
});

const MODEL_ID = "gemini-3-flash-preview";

// System prompt for the cosmetology AI assistant
const SYSTEM_PROMPT = `?? ? ???????????????? AI-?????????? ? ??????????? ??????.
???? ?????? ? ?????? ??????????????????? ???????????? ?? ????? ?? ????? ????.

?????? ???? ????????:
1. ?????? ??????? ?? ??????? ?????
2. ???????? ??? ????, ??????? ? ???????? ????????????
3. ?????????? ?????? ?????????? ? ??????????? ??????
4. ???????????? ? ????????? ?????????????????
5. ???????????? ??????: ??????? ??????, ????? ????????????
6. ????????? ?????? ??? ??????? ??????????
7. ???? ?? ?????? ? ?????????? ?????????? ? ???????????
8. ?? ?????????? ?????????? ??????, ?????? ???? ???????

?????? ??????:
- ??????? ?????? ????????
- 3-5 ?????????? ????????????
- ??????? ?????????? ??????? (????/?????)
- ?????????????? (???? ????)`;

export interface UserProfile {
  name?: string;
  age?: string;
  skinType?: string;
  problems?: string[];
  allergies?: string;
  goals?: string[];
}

export function formatUserContext(profile: UserProfile): string {
  const parts: string[] = [];

  if (profile.name) parts.push(`???: ${profile.name}`);
  if (profile.age) parts.push(`???????: ${profile.age}`);
  if (profile.skinType) parts.push(`??? ????: ${profile.skinType}`);
  if (profile.problems?.length) parts.push(`????????: ${profile.problems.join(", ")}`);
  if (profile.allergies) parts.push(`????????: ${profile.allergies}`);
  if (profile.goals?.length) parts.push(`????: ${profile.goals.join(", ")}`);

  return parts.length > 0 ? `??????? ????????????:\n${parts.join("\n")}` : "";
}

export interface ChatMessage {
  role: "user" | "assistant";
  content: string;
}

export async function generateRecommendation(
  userMessage: string,
  userProfile?: UserProfile,
  conversationHistory?: ChatMessage[]
) {
  const userContext = userProfile ? formatUserContext(userProfile) : "";

  // Map history to SDK format
  const messages = (conversationHistory || []).map((msg) => ({
    role: msg.role === "assistant" ? ("assistant" as const) : ("user" as const),
    content: msg.content,
  }));

  // Add current message with context if first message
  const contextualMessage =
    messages.length === 0 && userContext ? `${userContext}\n\n??????: ${userMessage}` : userMessage;

  const { text } = await generateText({
    model: gemini(MODEL_ID),
    system: SYSTEM_PROMPT,
    messages: [...messages, { role: "user", content: contextualMessage }],
    temperature: 0.7,
  });

  return {
    text,
    history: [
      ...messages,
      { role: "user", content: contextualMessage },
      { role: "assistant", content: text },
    ],
  };
}

export async function analyzeImage(
  imageBase64: string,
  mimeType: string,
  userProfile?: UserProfile
) {
  const userContext = userProfile ? formatUserContext(userProfile) : "";
  const normalizedImage = imageBase64.startsWith("data:")
    ? (imageBase64.split(",")[1] ?? imageBase64)
    : imageBase64;

  const prompt = `${userContext}

????????????? ??? ???? ???? ????. ????????:
1. ????? ????????? ????
2. ??????? ???????? (??????????? ????, ????, ??????????? ? ?.?.)
3. ??? ???? (???? ???????? ??????????)
4. ???????????? ?? ?????

???? ????????? ? ????????????? ? ????????? ????????????? ???????.`;

  const { text } = await generateText({
    model: gemini(MODEL_ID),
    system: SYSTEM_PROMPT,
    messages: [
      {
        role: "user",
        content: [
          { type: "text", text: prompt },
          { type: "image", image: normalizedImage, mediaType: mimeType },
        ],
      },
    ],
  });

  return text;
}
